

% -- Introduction - what you are solving and why it is important
\section{Introduction}
% no \IEEEPARstart
 
The SlugCam (previously called SWEETcam) network is a solar-powered wireless
smart camera network extending the concepts presented in
\cite{sweetcam_article}. Each individual camera in our network runs computer
vision algorithms and is capable of making decisions based on collected data and
environmental variables. Because the camera is able to recognize events through
computer vision algorithms, required data transmission is reduced enough so that
we can run the cameras on solar power and transmit data over a wireless network.
Since the camera can recognize important events, it also has the ability to
prioritize events of interest for immediate transmission to the server system.

This style of camera network is appealing for long-term outdoor deployment and
remote deployment in large areas with little activity. One possible deployment
involves monitoring wildlife where it may be desired to monitor a wide area with
the desire to track a small population. Our camera network improves upon simple
motion detection based camera networks by filtering out movement from
uninteresting events and allowing for the tagging of events to ease the burden
of looking through large amounts of video footage. In addition, we hope that the
reduction in collected and transmitted video footage will allow for the cameras
to completely rely on solar power thereby increasing the feasibility of long
term deployments in remote areas.

Since a major focus of the project is in assisting future research in multiple
fields, we are focusing on the extensibility of the system, its ease of use, low
cost, reliability, and reproducibility. We hope that any interested person could
build a network based on our work and customize it to their needs. In this light
we have made design decisions that allow people to make limited modifications in
one area of the system without worrying about the rest of the system and have
tried to make the system on a whole as developer friendly as possible. Our
system is open enough that other sensors could piggyback on our nodes and the
network software could run other sensor networks along with or instead of the
video and motion sensor networks that we are using. This means additional
features can be added without modifications to the core network.

Specifically our goal within the SlugCam project as a whole is to develop the
network software and a client application to support the cameras and provide a
usable interface into the system. In this paper we discuss the design and
implementation of this software.

\section{SlugCam System Background}

One of the main concepts around our system is that, unlike a traditional camera
network that constantly records video and transmits it to a central server, or
even simple cameras with only motion detectors, our camera network is able to
analyze video on the camera itself and make decisions regarding when and what to
record or transmit based on its determined importance, node state (such as the
amount of power remaining on the battery or the remaining amount of
storage on the camera node), or environmental variables determined from sensor
data (such as temperature, humidity, and other data of interest).

It is also important to understand the latency inherent in our system. High
priority video can be immediately transmitted, but cameras have the ability to
store low priority video until conditions change. Communication to a camera
node must also wait until that node decides to come alive, either due to
external events or periodic wakeups.

Our camera nodes themselves are built using as many off the shelf parts as
possible in order to allow future users to reconstruct our system as easily as
possible. We decided on the Raspberry Pi\cite{raspi_home} as a base for our
project due to its low cost, availability, and the balance of power and energy
use it provides. In order to optimize the power use even further, the Raspberry
Pi itself is motion activated. An MSP430 monitors a passive infrared sensor and
turns on the Raspberry Pi when motion is detected. The camera node software is
set to start when the Raspberry Pi is powered up. The camera node specific
software runs on a customized Linux distribution installed on the camera nodes
to minimize start up time and power consumption. This camera node specific
software begins communication with the network software where data collected
from the cameras is collected, stored, and presented to end user applications.

Currently our network relies on an existing 802.11g wireless network
infrastructure. This means in areas where a 802.11g network is available the
cameras are freely deployable. Though this restriction can be mitigated using
directional antennas, we understand that this is a major limitation. One of our
future areas of research will be allowing for the use of ad-hoc wireless
networks. The wireless networking hardware we are using already allows for this
feature and we will test the implementation of this feature and its power usage
in the future. We have also tried to keep the system architecture generic enough
that the system will work over different types of communication networks. We
hope that the general goal to minimize video footage recorded and to prioritize
communication of data will have application over any limited bandwidth network,
such as cellular networks and satellite data connections.

SlugCam is not the first project to attempt to accomplish many of these goals.
CITRIC\cite{CITRIC} is a similar smart camera project with a focus on running
computer vision algorithms on camera nodes and communicating over wireless and
other low-bandwidth networks, but without the focus on implementing a solar
energy source that the SlugCam project does.  The CITRIC paper also outlines
several other similar projects and has comparisons of them to their system.

FireWxNet\cite{FireWxNet} presents a solar-powered wireless sensor and visual
surveillance network designed for very remote deployment in the monitoring of
wildfires. It shares some design goals with our project but does not share the
focus on computer vision and automatic analysis of video data.

The authors of \cite{10.1109/DSD.2008.23} present a system that shares many of
the design goals of our project, including the desire to utilize alternative
power sources, wireless communication, and computer vision to create as
autonomous a camera node as possible.


%-- Body sections - 1-3 sections with titles relevant to your work. This should
%discuss the details of your contribution. This may be a new algorithm, a new
%design, or whatever you actually did. It can be 1 large section with
%subsections or a couple separate sections -- you decide.
%
\section{Software Overview}

All of the software for the SlugCam system can be broken into three main areas:
software that runs on the cameras themselves, the network software supporting
the system, and client applications that present collected data to the end
users. The focus of this paper is the network software and the client
application that we designed.

\section{Network Software Design}

One of the major goals for the network software design was to create a
network that is easily extensible by researchers who may not have much
experience working with network software. Our design decisions reflect this
desire along with the need to work with the restrictions of our hardware and
network choices.

\subsubsection{Modular Design}

We decided early on that designing our network software in a modular way would
afford us several benefits including ease of extensibility, ease of deployment,
and the testability of our system.

By clearly defining functional units and retaining a separation of duties
between separate units of code we help ease the development process. Not only
can development on separate modules occur in parallel, but developers can also
work on a module without needing knowledge of how other modules are coded. This
aspect becomes more important in our desire to create a system that is easily
extensible by future researchers who may not have the time or desire to fully
understand our code, but would like to add modules for their unique needs.

% Architecture Diagram
% TODO should caption be centered?
\begin{figure}[!t]
\centering
\includegraphics[width=2.5in]{software_organization}
\caption{High-Level Architecture of the SlugCam Software System}
\label{fig_netoverview}
\end{figure}

We chose to break apart network functionality into several main areas as shown
in figure~\ref{fig_netoverview}. The message server is the main server
responsible for communicating all textual data between the network and the
cameras and the video server receives the video data from the cameras. The API
server offers an HTTP interface to the network for end-user applications. All of
these modules interact independently and communicate through the data storage
layer. 

One of the disadvantages of this design is that to maintain true separation of
modules we lose the ability for modules to directly communicate.  Though for
many applications this is not important, it does make it difficult for client
applications to provide notification of updates without polling the data layer.
Since we are not running into issues with this it is not something that we are
looking to optimize currently, although several solutions are possible. One
would to be allowing the data layer to send notifications to the API server.  In
the current implementation this would mean that the servers would have to run in
the same process. This requirement could be removed by creating a notification
server that could broadcast updates to modules over a network connection. The
ability to send email notifications or text messages is not as problematic, as
this will be implemented at the data layer instead of existing across modules.

%Another disadvantage of our modular design is the loss of optimization that
%could be done. There are other problems similar to notification between modules
%that might be optimized with a more monolithic design, however Disadvantages, 

% Insert Workflow diagram

%Creating new modules

\subsubsection{Opportunistic Network Design}

Since various factors could inhibit communication to and from the camera nodes,
we are required to design a server system that works in a delay-tolerant manner.
To deal with these issues, we built all communication protocols in an
opportunistic way. The video and message servers constantly wait for incoming
connections from camera nodes and expect that those connections could be dropped
at any time. Any messages that need to be sent to the camera must wait until
that camera comes online, and as soon as the camera does come online we begin to
send it. This style of network further increases camera autonomy at the cost
immediate communication ability. It allows for many interesting optimizations,
such as reducing communication in low power situations and when only
non-interesting data has been collected. Cameras can also be set to come alive
on a timer to receive important control data from the network if needed to help
manage the communication latency inherent with this type of design.

\subsubsection{Network Transparency}

One of our goals is to make it easy for researchers to augment the camera nodes
with additional sensors without needing to modify the core network software. We
would like these developers to not have to worry about the network software, and
to have the opportunity to focus on their data collection and analysis systems.
To implement a new mode of data collection, a developer only needs to establish
a connection to the message server and send data. The network will recognize and
handle new data types as it does native SlugCam data types. Eventually our video
data collection system could be abstracted to generic binary data collection
which would allow further opportunities to future developers on our platform
without modifying the network itself.

\subsection{Data Layer}

The data layer is responsible for maintaining the persistence of the system. It
manages both textual data and the video data collected from the system. It also
plays an important role in connecting the individual modules of the system and
allowing them to communicate while remaining functionally independent.

The SlugCam network's data storage needs can be split into two major sections,
textual data and video data. Both of these types of data storage have unique
challenges and needs for a storage solution.

In order to consolidate storage code in a meaningful way, the data layer code
should exist as a Node.js module and should contain all the functions required
to access the data layer. Though this is not currently true in implementation,
it currently only manages the interface to the database for textual data and the
file system commands are done elsewhere.

\subsubsection{Textual Data}

Textual data in our system takes the form of what we call messages. Messages
encapsulate data communicated both to and from the cameras. Each message has
several required metadata fields, a type, and a data section. It is the design
of this message format that allows us to be so flexible in our stored data
types. All of the native SlugCam messages have a type and a specified structure
for the data section. The data layer is responsible for allowing us to query a
specific message type and it is up to the client to decide how to interpret the
data in a message. This goes along with the transparent network concept. It
means that for a new data type to be introduced into the system modifications
only need to be made to the camera node software and the client.

We decided to implement the textual data storage using an existing database
system to take advantage of optimizations already made for storing this kind of
structured data. The database system is further discussed in the methodology
section.

\subsubsection{Video Data}

The second portion of our storage layer is video storage. Video data and the
textual data are very different. We often want to search through and query
against large amounts of small messages whereas with video data each record
contains a relatively large amount of data and requires special work to process
and search though. In looking at methods we could use to store video data we
determined that simply storing video data on the file system of the operating
system would suit this project better than the alternatives, such as using a
database system.

%TODO weak
Since all metadata pertaining to a videos is textual data, it is stored in the
message system. This means that there is a set of data in the textual data
storage system containing all the metadata for a video. This set will contain a
video ID, which along with the camera name can be used to recall the required
video data from the file system. This means that we are able to retain the
advantages of a database for querying and searching though video data.

For our project, one of the advantages of storing the video data using
the file system is that we retain the ability to use third party video
processing tools without requiring a database wrapper to access the video. This
helps us in experimenting with different video formats and means that we can 
easily write scripts to process an entire library of collected video data.

% TODO bring in extensibility

\subsection{Message Server}

The message server is a TCP server that is responsible for textual communication
with the cameras. It transmits messages to and from camera nodes. This server
operates in an opportunistic manner, as the rest of the network software does.
This means that the server keeps a TCP port open ready to receive data and on
the first message it receives it will begin sending outgoing messages until
there are no more messages or the connection has been lost.

In an attempt to find a standard data format that would be easy to use for
future developers we wanted to use a standard data format instead of creating
our own. We found that using JSON to structure our messages met most of our
requirements. JSON is a standard, well defined, textual data format that is easy
to parse and human readable. Libraries for working with JSON exist in many
languages and it is not difficult to write libraries in languages that do not
already have support. JSON also allows for nested structures which opens up many
possibilities in structuring our message data fields.

% references and discuss

\subsection{Video Server}

The video server is a TCP server that is responsible for receiving video data
from the cameras. Unlike the message server, the video server only allows for
communication from cameras, thus it is simpler in design than the message
server.

The protocol used to receive messages is a very simple binary transfer protocol.
After a TCP connection is made the camera begins sending any pending videos.
Multiple videos can be transferred per connection and like the
message server a connection may be ended at any time without causing problems.

Currently after a connection is made the camera first sends its name as a null
terminated string, the camera then sends the video ID and video byte length as
unsigned 32bit integers, then sends the video data itself.  The camera can then
repeatedly send IDs, byte lengths, and video data for as many videos as it
likes. This is shown in table~\ref{video_protocol}.



\begin{table}[!t]
% increase table row spacing, adjust to taste
\renewcommand{\arraystretch}{1.3}
\caption{Fields Required for the Video Protocol}
\label{video_protocol}
\centering

\begin{tabular}{ | l || c | c | c | c | c | c |}
    \hline  
    Length & Variable & 32 bits & 32 bits & $Length_1$ & 32 bits & ...\\
    \hline                       
    Field & Camera Name & ID{1} & $Length_1$ & $Data_1$ & $ID_2$ & ...\\
    \hline  
\end{tabular}

\end{table}


We have designed several other protocols that work differently than our current
protocol. We have looked at adding the ability to break the data into pieces and
to send the pieces individually. The protocol we had originally designed worked
this way however, due to time constraints, we decided to implement our current
protocol first and to experiment with various algorithms to send fragmented
videos later. This way we could have a performance analysis of the different
algorithms and see how they worked in the system as a whole. One of the main
advantages of our current protocol is its simplicity. We will need to balance
the value of being able to power off mid-transfer without data loss and the code
complexity that a new protocol could add. With our current setup we have the
ability for the camera to make sure that a shutdown does not occur mid-way
through a video transfer and to prevent video transmission in a low battery
situation, so it is possible that other protocols may not offer enough benefit
to outweigh the extra complications to the system that they would create.

\subsection{API Server}

The API server provides a clearly defined interface into this potentially
complicated network. The API server is one of the points at which we were able
to create a more transparent design for future developers. Our API server
provides an HTTP interface to the network software that can be used by multiple
client types. We chose to use an HTTP interface due to its ubiquity in modern
computer systems. Future developers of the system have the ability to develop
clients in many different languages and frameworks. It also allows for the
possibility of running custom automated monitoring and video processing
applications without modifications to the core network.

\section{Client Application}

Our client application is designed to be a user-friendly interface to the large
amounts of fragmented data that this system has the ability to collect. We
wanted the client application to act as a showcase for the power of the system
and to show many of its unique features. It is also important that the client
application is well written and documented so that it can serve as a usage
example for the API server.

In order to present the cameras in an easy to understand way, we decided to
allow for the mapping of cameras and the display of system data on maps of the
monitored area. Since this system is designed to work with a large number of
cameras, having a list of cameras is not as intuitive as being able to see the
location of cameras and recognize where activity is happening on a more global
scale. The ability to implement mapping is an interesting application of our
transparent network feature. The mapping data is implemented only at the client
level, not requiring any input from the cameras or change to the networking
software. Our client application adds location data to cameras records, and is
able to then recall it at a later time.  This has the drawback that cameras must
be renamed when moved to a new location, however, since camera name is easily
configurable on the cameras, we did not see this as a major drawback.

We decided to build our client application as a single-page web application.
This application runs within a web browser, but only requires a connection to
the API server. This means that, though the application is built using web
technologies, the application itself is fully contained in the client's web
browser.

One of the main reasons we chose this approach is its flexibility. By designing
our application using standard web technologies we try to remain as platform
agnostic as possible. We hope to build an application that can work well across
operating systems and browsers.

Since our application is a web application it can easily be hosted by a server
included with the network software. This approach means that no end-user
configuration is needed to run the application and that the application can be
accessed from any web browser with access to the server. This could be a very
clean and easy design for many uses. This is the method we are currently using
in our testing, and we have included hooks in the script that starts the other
servers that also starts up a static server hosting or client application.

Since the our application runs entirely in the web browser, there is also the
possibility of running the application from a client's local disk. Using
frameworks such as node-webkit\cite{nw_home} or Atom Shell\cite{atom_home} we
could also include features that are not possible in a normal web application
such as the ability to save video files locally without prompting the user for
location (could be useful if bulk saving many video files), or deeper desktop
integration than web browsers allow for.

Another benefit of using web technologies is mobile support. By sticking close
to web standards we have been able to create a client application that is usable
on tablets and mobile phones. In fact, we have been able to use the HTML5
geolocation API to allow for setting the location of a camera based on GPS data
from a smart phone. This means that when setting up a camera, the user can log
into the web application, open the camera configuration, hit a button, and the
camera location is automatically adjusted (manual configuration is also
available). We will have to continue to analyze whether it is worthwhile to
support both desktop and mobile clients in our application.


%-- Methodology - Your results will have some experiments or a demonstration.
%What tools did you use to create your software, simulator, or parts did you use
%to create your prototype?
\section{Methodology}

% TODO a lot of opinion
In our implementation of the network software we decided to use the Node.js
JavaScript framework. We went with this choice for several reasons. Node.js
offers many built in tools for writing network software while remaining more
lightweight than many alternatives. Facilities for creating TCP and HTTP
servers, network security, and many other essentials exist in the standard
Node.js libraries. Using these facilities does not require much boilerplate code
and is more succinct, and we believe more approachable, than in some
alternatives. The developer community around Node.js is active and we were able
to find packages for many useful development and network related tasks. In our
experience many of the packages we found focused on solving a specific task
which allowed us to bring in well-tested packages without adding a large amount
of unnecessary code to the project.

One of the drawbacks of JavaScript is that the dynamic type system removes the
possibility of static type checking. This introduces a class of errors that can
be detected by a compiler or other tools in statically typed languages such as C
or Java. To help avoid many of the errors associated with the dynamic nature of
JavaScript we use linting tools, such as JSHint, to warn us of common errors and
patterns that frequently lead to error. We also use thorough documentation to
aid in preventing many of these types of errors, and we are attempting to clearly
define all interfaces and functions in documentation.  We are also planning on
using prolific unit testing to ensure the reliability of or network code base in
addition to end-to-end testing over the entire system.

In our current implementation of the system we chose MongoDB\cite{mongo_home}
for textual data storage. MongoDB offers several advantages in our situation.
First of all, MongoDB stores records as documents, which are very similar to
JSON objects.  This closely matches our desire to store our messages in a
flexible way and the use of JSON as a communication format. Since MongoDB is
designed around this style of data storage, and offers tools to easily and
efficiently query data stored in this manner, it is a choice that has allowed us
good performance and rapid development time. It makes it very easy to implement
the flexibility we desire in our message format.

For the client application we decided to use AngularJS\cite{angular_home} as our
main framework. AngularJS is a JavaScript framework developed by Google. It aids
in the creation of single-page client based web applications and allows us to
build user interfaces in a more declarative way than in traditional web
programming. This declarative approach to user interface design makes it much
easier for us to experiment with different interface ideas rapidly. AngularJS is
well documented and supported by Google, and has an active community of users
outside of Google. Using the AngularJS framework has helped us create efficient,
modular code that is easy to maintain.

%-- Results - The measurements of results including tables, pictures, or other
%information.
\section{Results}

Using the design we above we were able to successfully upload videos and
messages using camera simulation software. An actual deployment test is pending
the completion of the camera nodes. The camera simulation software is able to
generate messages and send generated video into the network that can then be
viewed in the client application. This simulation software is a very useful tool
not only in the development of our network software, but also in its testing.

We were also able to complete a basic client application and will continue to
add in features along with the development of the system as a whole. Our client
application currently supports the mapping features discussed above and the
ability to view collected messages and video. Screenshots of the current client
application are shown in figure~\ref{fig_screens}.


\begin{figure}[!t]
\centering
\includegraphics[width=3in]{screenshots}
\caption{Screenshots of the SlugCam Client Mapping and Video Capability}
\label{fig_screens}
\end{figure}

